{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codingws3_ml",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxc5ZoD2lxNOrIHrFe/g1X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatriceadel/ppsdcw3/blob/main/codingws3_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Machine Learning w/ Python**"
      ],
      "metadata": {
        "id": "4-TJLve5j5xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Apa itu Machine Learning?**\n",
        "\n",
        "\n",
        ">The use and development of computer systems that are able to **learn and adapt without following explicit instructions**, by using **algorithms and statistical models** to analyse and draw inferences from **patterns in data**. \n",
        "\n",
        "-*Oxford Dictionaries*\n",
        "\n",
        "<img src=\"https://volcanohong.github.io/content/images/2016/ml_process.png\" width=600 height=300/>"
      ],
      "metadata": {
        "id": "P4Ch4mz-Qm5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries & Tools Python untuk Machine Learning**\n",
        "\n",
        "\n",
        "*   **NumPy & SciPy**: General-purpose numerical computation\n",
        "*   **Pandas**: Data analysis & manipulation\n",
        "*   **Matplotlib & Seaborn**: Data visualization\n",
        "*   **Scikit-Learn**: Machine learning functions and algorithms\n",
        "*   **Tensorflow**: Machine learning models\n",
        "*   **PyTorch**: Machine learning, computer vision, & natural language processing\n",
        "*   **Keras**: Machine learning, deep learning, neural networks\n",
        "\n"
      ],
      "metadata": {
        "id": "wBpEygDBRTvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Studi Kasus**\n",
        "\n",
        "Untuk workshop ini, kita akan mengaplikasikan beberapa macam algoritma pada dataset **'Breast Cancer Wisconsin'** yang diambil dari [*UCI Machine Learning Repository*](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original))\n",
        "\n",
        "Dataset dapat di download melalui link [ini](https://raw.githubusercontent.com/beatriceadel/ppsdcw3/main/breast-cancer-wisconsin.csv)\n",
        "\n",
        "Setelah data sudah didownload, kita bisa memulai dengan mengimport libraries yang akan kita gunakan: NumPy, Pandas, Matplotlib, dan Seaborn."
      ],
      "metadata": {
        "id": "k07RoFpkVKAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library - library yang akan digunakan\n"
      ],
      "metadata": {
        "id": "2VExtS1IboeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mengidentifikasi Masalah\n",
        "\n",
        "Pertama - tama, dalam membangun sebuah machine learning model, kita perlu mengidentifikasi terlebih dahulu masalah apa yang ingin kita selesaikan dengan model yang kita buat.\n",
        "\n",
        "**Masalah - masalah paling umum dalam Machine Learning:**\n",
        "\n",
        "*   *Classification*\n",
        "*   Regression\n",
        "*   Clustering\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Frank-Nielsen-3/publication/314626729/figure/fig1/AS:810830673244160@1570328505835/The-three-pillars-of-learning-in-data-science-clustering-flat-or-hierarchical.ppm\" width=600 height=400/>"
      ],
      "metadata": {
        "id": "IL4497yvW-QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca data\n"
      ],
      "metadata": {
        "id": "4O-jRMuRb_ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memproses Data\n",
        "Dalam machine learning, sebelum kita membangun model, kita juga perlu melakukan **data pre-processing.**\n"
      ],
      "metadata": {
        "id": "X8vNYexrWzLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memeriksa Missing Values\n",
        "\n",
        "Missing values atau data yang kosong dapat mengganggu proses komputer dalam mempelajari data. Maka dari itu, ada beberapa cara yang dapat kita lakukan untuk mengatasi missing values:\n",
        "\n",
        "\n",
        "*   Menghapus instansi data (row) yang mengandung missing value\n",
        "*   Mengganti missing value dengan rata - rata dari data atribut tersebut\n",
        "*   Mengganti missing value dengan sebuah konstanta (constant)\n",
        "\n",
        "Kita dapat memfilter missing values dengan menggunakan cara yang sama seperti ketika kita membuat kondisi saat menulis `if` statement."
      ],
      "metadata": {
        "id": "v97DA050jtoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyeleksi missing values\n"
      ],
      "metadata": {
        "id": "m7L7F0XKkqP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Latihan**\n",
        "\n",
        "Coba periksa apakah kolom ```size_uniformity``` dan ```shape_uniformity```mengandung missing values atau tidak. \n"
      ],
      "metadata": {
        "id": "zJMkR0HzvKcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jawaban\n"
      ],
      "metadata": {
        "id": "6ZjWIUsqv9I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus data dengan missing values\n"
      ],
      "metadata": {
        "id": "XBwpbbTxqAdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat korelasi antar fitur/kolom (bar chart)\n",
        "\n",
        "Terkadang ada fitur / kolom di dataset yang kita miliki yang sebenarnya tidak relevan untuk proses training. \n",
        "\n",
        "Kita dapat melihat fitur mana saja yang relevan dan tidak melalui visualisasi data dengan menggunakan [Matplotlib](https://matplotlib.org/) dan [Seaborn](http://seaborn.pydata.org/). "
      ],
      "metadata": {
        "id": "L4Rdj6KHt4OW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita dapat melihat korelasi antara satu fitur dengan target fitur kita (class) dengan menggunakan **bar chart**."
      ],
      "metadata": {
        "id": "LWEv9uXi0dav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan bar chart untuk melihat korelasi clump_thickness dengan class\n"
      ],
      "metadata": {
        "id": "fNS0XmVp0wmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Latihan**\n",
        "\n",
        "Tampilkan bar chart yang menunjukkan korelasi antara fitur `size_uniformity` dengan target fitur kita (`class`)\n"
      ],
      "metadata": {
        "id": "yVq6HiVu26JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jawaban \n"
      ],
      "metadata": {
        "id": "8W8djo3f2p63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Melihat korelasi antar fitur/kolom (heatmap)\n",
        "\n",
        "Untuk melihat korelasi antara semua fitur, bentuk visualisasi yang paling mudah adalah dengan menggunakan **heatmap.** Dalam sebuah heatmap, angka *+1* menunjukkan tingkat korelasi positif yang paling kuat, angka *-1* mennjukkan tingkat korelasi negatif yang paling kuat, dan angka *0* mengindikasikan bahwa tidak ada korelasi antara kedua fitur tersebut. "
      ],
      "metadata": {
        "id": "kaTLIkLo31_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan heatmap\n"
      ],
      "metadata": {
        "id": "lelLAYCTyF4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari heatmap di atas, kita dapat melihat bahwa fitur \"id\" dan \"mitoses\" tidak memiliki korelasi yang kuat dengan \"class\". Jadi, kita dapat menyeleksi fitur/kolom yang akan kita gunakan dalam proses training sebagai berikut:"
      ],
      "metadata": {
        "id": "Wf0c1myv4Mh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleksi fitur\n"
      ],
      "metadata": {
        "id": "YtzWXO-fCJWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Membangun Machine Learning Model\n",
        "\n",
        "Untuk membangun machine learning model kali ini, kita akan mencoba menggunakan beberapa algoritma yang tersedia di [scikit-learn](https://scikit-learn.org/stable/index.html). Pertama, kita import terlebih dahulu tools yang akan kita gunakan."
      ],
      "metadata": {
        "id": "idy0kbfk8Isb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dari scikit-learn\n"
      ],
      "metadata": {
        "id": "lVlc33Sl_kxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita ingin membuat model berdasarkan fungsi **y = f(x)** dimana ketika input x (data baru) diterima, machine learning model kita dapat menentukan y (class) berdasarkan data yang sudah dipelajari di proses training. \n",
        "\n",
        "Untuk itu, kita juga perlu membagi dataset kita menjadi \"train set\" dan \"test set\". Train set akan digunakan untuk melatih machine learning model kita, sedangkan test set akan digunakan untuk mengevaluasi model kita. \n",
        "\n",
        "Dalam percobaan kita, kita akan menggunakan fungsi `train_test_split` untuk membagi secara random (`random_state = 42`), dan kita akan tentukan jumlah test set sebanyak 20% dari total data (`test_size = 0.2`)"
      ],
      "metadata": {
        "id": "xi4pGp89CyPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan pembagian data"
      ],
      "metadata": {
        "id": "KGrkM5fRDoNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah itu, kita perlu:\n",
        "\n",
        "1.   Menentukan algoritma klasifikasi / classifier (`clf`) yang akan digunakan. \n",
        "2.   Melatih classifier `clf` dengan train dataset `x_train` dan `y_train`.\n",
        "3.   Menggunakan data `x_test` untuk melihat hasil prediksi model.\n",
        "4.   Mengestimasi akurasi model dengan test dataset dan **cross-validation**.\n",
        "\n",
        "\n",
        "\n",
        "Apa itu cross-validation? \n",
        "\n",
        "Cross-validation adalah salah satu cara untuk mengevaluasi machine learning model. Dalam cross-validation, dataset dibagi menjadi beberapa subset (misal *n*), *1* subset akan disimpan untuk validasi atau test, dan *n-1* subset lainnya akan digunakan untuk proses training. Proses ini diulang hingga semua subset sempat digunakan untuk validasi, dan rata - rata akurasi dari tiap repetisinya adalah hasil akurasi akhir."
      ],
      "metadata": {
        "id": "X1juNSilEyP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Nearest Neighbor\n",
        "\n",
        "Nearest Neighbor adalah alogritma yang cara kerjanya adalah mencari \"tetangga\" terdekat untuk menentukan data yang baru diterima akan diklasifikasikan ke kelompok yang mana. \n",
        "\n",
        "<img src=\"http://3.bp.blogspot.com/-ZslDMqm5M9o/T8ja_f_fALI/AAAAAAAAAt4/z7w55YAZXpw/s1600/p1.png\" width=400 height=300/>\n",
        "\n",
        "Kita dapat menggunakan algoritma ini dengan mengimport `KNeighborsClassifier` dari  `sklearn.neighbors`"
      ],
      "metadata": {
        "id": "5Boc-g7a_1k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nearest Neighbor\n"
      ],
      "metadata": {
        "id": "gBbKX1OzA-lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Decision Tree\n",
        "\n",
        "Decision Tree adalah algoritma yang cara kerjanya adalah menyusun suatu struktur hierarki untuk menentukan data yang baru diterima akan diklasifikasikan ke kelompok yang mana. \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/6810/1*1tGLoeGg4cDwQXSLSgD5Zg.png\" width=300 height=150/>\n",
        "\n",
        "Kita dapat menggunakan algoritma ini dengan mengimport `DecisionTreeClassifier` dari `sklearn.tree`"
      ],
      "metadata": {
        "id": "xHK6KRKE_8QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "yC4G1RUDJGsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest\n",
        "\n",
        "Random Forest adalah algoritma yang dibangun dengan beberapa decision tree, dimana output dari seluruh decision tree digabung menjadi 1 output. \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2612/0*f_qQPFpdofWGLQqc.png\" width=300 height=200/>\n",
        "\n",
        "Kita dapat menggunakan algoritma ini dengan mengimport `RandomForestClassifier` dari `sklearn.ensemble`"
      ],
      "metadata": {
        "id": "tjRfuhyxJYC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "YO9nHfx1JZNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Naive Bayes\n",
        "\n",
        "Naive Bayes adalah algoritma yang mengaplikasikan **Bayes' Theorem**, dimana cara kerjanya adalah menghitung probabilitas sesuatu berdasarkan data yang sudah diketahui. Probabilitas inilah yang menentukan data yang baru akan diklasifikasikan ke kelompok yang mana. Kita dapat menggunakan algoritma ini dengan mengimport `GaussianNB` dari `sklearn.naive_bayes`"
      ],
      "metadata": {
        "id": "sIPRYUg1Ip1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "wFp0PpDhIpB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perbandingan hasil akurasi\n"
      ],
      "metadata": {
        "id": "NEuJQv28Ji1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}